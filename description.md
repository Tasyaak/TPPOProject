# Рекомендательная система по исправлению ошибок компиляции C++

## Постановка задачи

Необходимо разработать оконное приложение, которое работает на основе алгоритмов машинного обучения, определяет первую найденную ошибку компиляции и номер строки исходного кода на языке `C++`, где возникает данная ошибка, и выдаёт текстовую рекомендацию по её исправлению.

На вход приложения подаётся исходный код программы на `C++`, на выходе возвращается текстовая рекомендация по исправлению найденной ошибки.

Первую по порядку ошибку в исходном коде можно находить с помощью различных `C++` компиляторов, используя разные версии стандарта `C++`. В нашей работе мы ограничимся использованием компилятором `MSVC (Visual Studio 2022)` с версией `C++14`.

При разработке приложения рассматривались следующие коды ошибок: `C2065`, `C3861`, `C2143`, `C2146`, `C2059`, `C1075`, `C1083`, `C2131`, `C2440`, `C2446`, `C2676`, `C2678`, `C2679`. Они использовались для группировки рекомендаций.

## Используемые программные средства и библиотеки

Программа была реализована на языке `Python`, для хранения обучающих данных и разработанных моделей использовалась база данных `SQLite3`. Для компиляции исходного кода вызывается компилятор `MSVC` через консоль `Developer Command Prompt for VS 2022` с помощью библиотеки `subprocess`, для парсинга исходного кода используется библиотека `libclang`.

Для обработки датасета и последующего хранения данных использовались библиотеки `pandas`, `numpy`, `concurrent` и `pyarrow`. Для предобработки данных и обучения моделей использовалась библиотека `sklearn`, для визуализации результатов классификации использовалась `matplotlib` и для сохранения и загрузки моделей использовалась `joblib`.

Оконное приложение разрабатывалось с помощью библиотеки `tkinter`, использовалась среда разработки `VS Code`, процесс обучения моделей происходил на платформе `Google Colab`.

## Описание датасета

Построение обучающих данных основано на датасете `Project CodeNet`, являющимся одним из крупнейших открытых наборов данных программного кода от `IBM`. Он включает примерно 14 миллионов примеров кода для около 4000 задач соревнований по программированию, собранных с онлайн-соревнований систем `AIZU` и `AtCoder`. Датасет охватывает 55 языков программирования, но наиболее широко представлен `C++` (примерно 57% от общего числа). Каждая программа хранится в отдельном исходном файле, а к ней прилагается запись в CSV-метаданных с различной информацией - ID задачи и пользователя, путь к файлу, время, размер кода и статусы компиляции и проверки.

Данный датасет можно найти по ссылке https://github.com/IBM/Project_CodeNet.

Из датасета `CodeNet` были отфильтрованы `C++` программы со статусом `Compile Error`, а также были извлечены исходные коды из файлов по указанным путям к ним, из которых были удалены все комментарии и которые затем были добавлены в качестве нового столбца. Полученный `DataFrame` был сохранён в формате `parquet`.

## Преобразование датасета

Каждая `C++` программа, код которой содержится в отдельной записи датасета, была откомпилирована и в результате были добавлены новые столбцы с текстом ошибки компиляции и номером строки, в которой была обнаружена ошибка.

Было посчитано количество программ с одинаковыми кодами ошибок и были рассмотрены первые 13 в отсортированном списке по убыванию количеству примеров. Далее рассматривалась только часть датасета с указанными ранее кодами ошибок.

Датасет был разделён на две части - программы, в которых использовались макросы, и программы без макросов. Оно было необходимо для ускорения парсинга программ, т.к. часть датасета без макросов была значительно больше и в параметрах метода `parse`, содержащегося в библиотеке `libclang`, можно отключить опции для обработки макросов, что ускоряет процесс парсинга.

### Парсинг датасета

Для каждого исходного кода программы сначала вызывается функция `find_smallest_cursor_by_line`, которая находит наиболее локальный `Cursor` (указатель на узел семантического дерева (`AST`-дерева), например, объявление, выражение, оператор, тип, директива `include` и т.п.) в строке с ошибкой компиляции, после этого извлекаются `core_info`, в которой хранится вид узла, название в коде, тип данных, и `cursor_meta`, в которой хранится метаданные узла, и находится `parent_chain`, представляющая собой цепочку из видов узлов родительских `Cursor`'ов с глубиной вложенности 6.

Далее строится и нормализуется список `local_tokens_norm` из `Token`'ов (лексических единиц), рассматриваемых в окрестности строки с ошибкой с радиусом 2-4 строк, и синтезируются глобальные признаки, состоящие из `include`, макросов, псевдонимов типа и различных счётчиков.

Результаты парсинга датасета с соответствующим индексом записи `DataFrame` сохраняются в формате `jsonl` для возможности объединения датасета с полученным `jsonl` файлом.

### Разметка датасета

Для рассматриваемых кодов ошибок были составлены рекомендации по исправлению ошибок компиляции с данными кодами, при этом одному и тому же коду ошибки может соответствовать несколько различных рекомендаций. Была сделана сортировка рекомендаций по исправлению ошибок с одним и тем же кодом по частоте соответствующих ошибок в датасете. Отсортированные рекомендации были сохранены в базу данных.

По умолчанию в датасете в качестве нового столбца устанавливалась метка, соответствующая рекомендации по исправлению наиболее встречающихся ошибок с данным кодом. Дальнейшее уточнение разметки датасета производилась с помощью `label functions` (`lf`), каждая из которых соответствует определённой рекомендации и представляет собой эвристическую функцию, которая автоматически проставляет метки записям в датасете на основе текста ошибки и исходного кода, когда ручная разметка трудоёмка или невозможна в нужном объёме.

### Ручная токенизация

Полученный компиляцией `error_text`, содержащий код и описание ошибки, нормализовывался, заменяя ключевые слова на шаблоны, и токенизировался, разделяя слова по пробелам и удаляя знаки препинания.

Из полученных парсингом `core_info`, `cursor_meta`, `parent_chain`, `local_tokens_norm` и глобальных признаков строились текстовые и числовые признаки, используемые для дальнейшей векторизации, при этом текстовые признаки токенизировались без помощи библиотек.

Эти токены и числовые признаки были добавлены в размеченный датасет в качестве новых столбцов и полученные обучающие данные сохранялись в базу данных.