data:
  sql: |
    SELECT label, error_text_tokens, ctx_tokens, ctx_numeric
    FROM training_data
    WHERE is_in_train = 1


features:
  lowercase: false
  naive_bayes_compatible: false

  for_ctx_numeric:
    mode: "DictVectorizer"
    scale: "StandardScaler"
    vectorizers:
      DictVectorizer:
        sparse: true
    scaling:
      StandardScaler:
        with_mean: false
    
  for_ctx_tokens:
    mode: "CountVectorizer"
    ngram_range: [1, 4]
    tokenizer: "identity"
    preprocessor: "identity"
    token_pattern: null
  
    TfidfVectorizer:
      smooth_idf: true
      sublinear_tf: true # использовать логарифмическую зависимость для TF
      max_df: 1.0 # не отсекать
      min_df: 1   # не отсекать
    
    CountVectorizer:
      max_df: 1.0 # не отсекать
      min_df: 1   # не отсекать
    
    HashingVectorizer:
      n_features: 1048576
  
  for_error_text:
    mode: "CountVectorizer"
    ngram_range: [1, 5]
    preprocessor: "identity"
    tokenizer: "identity"
    token_pattern: null

    TfidfVectorizer:
      smooth_idf: true
      sublinear_tf: true # использовать логарифмическую зависимость для TF
      max_df: 1.0 # не отсекать
      min_df: 1   # не отсекать
    
    CountVectorizer:
      max_df: 1.0 # не отсекать
      min_df: 1   # не отсекать
    
    HashingVectorizer:
      n_features: 1048576
      alternate_sign: true


report:
  save_models_table: false
  metrics:
    - "accuracy"
    - "f1_weighted"
    - "roc_auc_ovr_weighted"


cross_val_score:
  strategies:
    - name: "stratified"
      type: "StratifiedKFold"
      n_splits: 5
      shuffle: true
      random_state: 42
    - name: "plain"
      type: "KFold"
      n_splits: 5
      shuffle: true
      random_state: 42
  n_jobs: -1


active_model: "log_regression"


training:
  cv_strategy: "stratified"
  tuning:
    method: "grid"               # "grid" | "halving_grid | "random" | "halving_random" | "none"
    scoring: ["accuracy", "f1_weighted", "roc_auc_ovr_weighted"]
    refit: "f1_weighted"
    n_jobs: -1
    verbose: 1
    error_score: "raise"


models:
  log_regression:
    type: "sklearn.linear_model.LogisticRegression"
    params:
      class_weight: "balanced"
    grid:
      - solver: ["lbfgs"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l2"]
        max_iter: [100, 200, 500, 1000, 10000]
      - solver: ["liblinear"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l2", "l1"]
        max_iter: [100, 200, 500, 1000, 10000]
      - solver: ["newton-cg"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l2"]
      - solver: ["newton-cholesky"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l2"]
        max_iter: [100, 200, 500, 1000, 10000]
      - solver: ["sag"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l2"]
        max_iter: [5000, 10000]
      - solver: ["saga"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["elasticnet"]
        max_iter: [5000, 10000]
        l1_ratio: [0.1, 0.2, 0.5, 0.9]
      - solver: ["saga"]
        C: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
        penalty: ["l1", "l2"]
        max_iter: [5000, 10000]
    halving_grid:
      factor: 3
      min_resources: "exhaust"
      scoring: "f1_weighted"
    halving_random:
      factor: 3
      min_resources: "smallest"
      scoring: "f1_weighted"


  support_vector_machine:
    type: "sklearn.svm.SVC"
    params:
      class_weight: "balanced"
    grid:
      - kernel: ["linear"]
        C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]
      - kernel: ["rbf"]
        C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]
        gamma: ["scale", "auto", 0.001, 0.01, 0.1, 1, 10]
      - kernel: ["poly"]
        C: [0.1, 1, 10, 100]
        gamma: ["scale", "auto"]
        degree: [2, 3, 4]
        coef0: [0, 1, 2]
    halving_random:
      factor: 4
      min_resources: "smallest"
      aggressive_elimination: true


  knn:
    type: "sklearn.neighbors.KNeighborsClassifier"
    params:
      metric: "minkowski"
      n_jobs: -1
    grid:
      - n_neighbors: [1, 3, 5, 7]
        weights: ["uniform", "distance"]
        algorithm: ["auto", "ball_tree", "kd_tree"]
        p: [1, 2, 3]
        leaf_size: [10, 20, 30, 40, 50]
    halving_grid:
      factor: 4
      min_resources: "smallest"
    halving_random:
      factor: 4
      min_resources: "smallest"


  random_forest:
    type: "sklearn.ensemble.RandomForestClassifier"
    params:
      class_weight: "balanced"
      random_state: 42
      n_jobs: -1
    grid:
      - n_estimators: [50, 100, 150]
        max_depth: [null, 5, 10, 15]
        min_samples_split: [2, 5, 10]
        min_samples_leaf: [1, 2, 4]
        max_features: ["sqrt", "log2"]
        class_weight: ["balanced", null]
        bootstrap: [true, false]
    halving_grid:
      factor: 2
      resource: "clf__n_estimators"
      min_resources: 30
      max_resources: 300
    halving_random:
      factor: 2
      resource: "clf__n_estimators"
      min_resources: 30
      max_resources: 300
      n_candidates: 60